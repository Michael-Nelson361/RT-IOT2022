{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac4912c-b7cd-4919-ba60-ade6cb418e3e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The dataset I am using for this project will be the RT-IoT2022 dataset, as found in the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/942/rt-iot2022). The data is derived from a real-time Internet of Things (IoT) infrastructure. The data collected is representative of both normal network traffic as well as simulated attack scenarios.\n",
    "\n",
    "There are 123,117 instances within this dataset with 83 different features. There are no missing values.\n",
    "\n",
    "## Questions being asked:\n",
    "1. What is the question you hope to answer? \n",
    "    - In light of advancements in AI, CyberSecurity is needed more than ever. Therefore, the question I hope to answer are what are some of the attack patterns and indicators that a threat actor might have when launching an attack on a network?\n",
    "2. What data are you planning to use to answer that question? \n",
    "    - The dataset is the RT-IoT2022 dataset, which is real world data collected for the purpose of helping train Intrusion Detection Systems (IDS).\n",
    "3. What do you know about the data you're using so far? \n",
    "    - I recognize some of the features and attributes from my studies as an IT specialist, and I have an idea of how these features and attributes may relate to each other.\n",
    "4. Why did you choose this topic? \n",
    "    - I am continuing to expand my studies in the IT field and currently am studying to take the CompTIA A+ certification exam. Therefore, understanding this dataset and modeling it may allow me further insights into the inner workings of networks and security."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9a378-698a-4844-bcca-585dfe32ec34",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Wrangling\n",
    "\n",
    "Wrangling will comprise of 2 parts: Acquisition of the data and then Preparation of the data.\n",
    "\n",
    "In acquisition, I will download and unpack the data, then build functions to import the data into the wrangle notebook. In this step also, I will take a brief analysis of the data.\n",
    "\n",
    "In preparation, I will split the data into a training, validation, and test set. I will then conduct a mild amount of surface level research into the variables to determine relevancy of certain variables to predicting a cyber attack may be happening.\n",
    "\n",
    "## Acquisition: *April 26*\n",
    "- [X] Download data and check formatting\n",
    "- [X] Import data into notebook and identify target variable\n",
    "- [X] Create function to import the data\n",
    "- Date of completion: April 26, 2024\n",
    "\n",
    "## Preparation: *April 27-29*\n",
    "- [X] Split the data into train, validate, and test sets\n",
    "- [X] Create (or recycle) a function to split the data\n",
    "- [ ] Identify the variables and their roles in the training set\n",
    "- [ ] Identify the correlation of the variables with the target variable\n",
    "- [ ] Develop questions about the data (5-10 questions)\n",
    "- [ ] Make predictions about the data\n",
    "- [ ] Create a function that uses the import function, then cleans and prepares the data\n",
    "- [ ] Export everything to wrangle.py\n",
    "- Date of completion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0794a-a8de-433c-8114-3a96492f2eef",
   "metadata": {},
   "source": [
    "# Exploration And Pre-Processing\n",
    "In these two steps, I will use the prepared data and answer questions I developed within the preparation and planning stage. Having answered these questions, I will then move on to the pre-processing stage, during which I will use functions from SciKitLearn as well as prior knowledge to build functions that encode the data for modeling.\n",
    "\n",
    "Both steps will be comprised of two separate notebooks.\n",
    "\n",
    "## Exploration: *April 30-May 7*\n",
    "- [ ] Utilize the questions to perform targeted exploration\n",
    "- [ ] Create 3-5 different graphs and statistical tests to answer questions\n",
    "- [ ] Turn each question answered into a function\n",
    "- [ ] Export each function into explore.py\n",
    "- Date of completion:\n",
    "\n",
    "## Pre-processing: *May 8-May 10*\n",
    "- [ ] Process datasets for modeling\n",
    "- [ ] Run analysis to determine potential irrelevant features\n",
    "- [ ] Drop decided unnecessary features\n",
    "- [ ] Encode datasets for modeling\n",
    "- [ ] Create functions for pre-processing\n",
    "- [ ] Add functions to model.py\n",
    "- Date of completion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b293f-2a05-4b2c-b9f1-9bf6c5d4d6b7",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## *May 11-12*\n",
    "In this final step of analysis, I will go through the selection process to choose the most appropriate algorithms equipped to handle and process the data provided. The process will include choosing 10 algorithms and test them using small and simple changes to the algorithm, following which I will then select the best 3 and conduct more extensive hyperparameter testing.\n",
    "\n",
    "- [ ] Make a selection of 10 algorithms to test (using simple algorithm configurations)\n",
    "- [ ] Select 3 algorithms with best average performance and apply advanced algorithm configurations\n",
    "- [ ] Use cross validation and pipeline to evaluate models\n",
    "- [ ] Isolate the best model and use on test dataset\n",
    "- [ ] Build functions for modeling \n",
    "- [ ] Add functions to model.py \n",
    "- Date of completion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd3842-ce98-4843-bcc4-5e5f9f6c33f7",
   "metadata": {},
   "source": [
    "# Delivery\n",
    "- [ ] Build notebook presentation ***May 13***\n",
    "- [ ] Prepare speech ***May 14***\n",
    "- [ ] Practice presentation ***May 15***\n",
    "- [ ] Conduct presentation ***May 16, 2024***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17c52f-6ea6-41fe-93ee-21734d6740d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
